{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilabel classification with text data using AutoML NLP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Connect to Azure Machine Learning Workspace\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install azure-identity\n",
    "from azure.identity import DefaultAzureCredential \n",
    "# pip install azure-ai-ml\n",
    "from azure.ai.ml.constants import AssetTypes \n",
    "from azure.ai.ml import automl, Input, MLClient"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Configure workspace details and get a handle to the workspace\n",
    "\n",
    "To connect to a workspace, we need identifier parameters:\n",
    "- A subscription.\n",
    "- Resource group.\n",
    "- Workspace name. \n",
    " \n",
    "We will use these details in the `MLClient` from `azure.ai.ml` to get a handle on the required Azure Machine Learning workspace. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLClient created\n"
     ]
    }
   ],
   "source": [
    "credentials = DefaultAzureCredential()\n",
    "subscription_id = 'a7ef3688-af58-4835-953c-e51f219fbd0f'\n",
    "resource_group_name = \"BigData_resource_group\"\n",
    "workspace = \"BigData_workspace\"\n",
    "try:\n",
    "    ml_client = MLClient(credentials, subscription_id, resource_group_name, workspace)\n",
    "    print(\"MLClient created\")\n",
    "except Exception as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: Paper submission systems (such as CMT, OpenReview, etc.) require the users to upload paper titles and paper abstracts and then specify the subject areas their papers best belong to. \n",
    "\n",
    "Our model will be trained on a dataset of paper titles and abstracts and their corresponding subject areas to classify/suggest what category corresponding papers could be best associated with.\n",
    "\n",
    "Our dataset is called 'arxiv_data.csv' and can be downloaded from [this link](https://www.kaggle.com/spsayakpaul/arxiv-paper-abstracts).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Filter out less common labels, and save the preprocessed dataset to a new file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ast\n",
    "# import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from collections import Counter\n",
    "# from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# # We want to filter out less common labels from a dataset of arxiv papers, and then save the preprocessed dataset to a new CSV file.\n",
    "# N = 5  # the number of most popular labels to keep\n",
    "\n",
    "# # Read the dataset\n",
    "# datasetPath = './data/arxiv_data.csv'\n",
    "# data = pd.read_csv(datasetPath)\n",
    "# # Convert the labels from strings to lists\n",
    "# data[\"terms\"] = data[\"terms\"].apply(ast.literal_eval) # ast.literal_eval: is used to convert the string representation of a list of labels to an actual list.\n",
    "\n",
    "# # Convert the list of labels into a binary matrix \n",
    "# transformer = MultiLabelBinarizer(sparse_output=True) # is used to convert the list of labels into a binary matrix. This is necessary to use the labels as input to a machine learning algorithm.\n",
    "# transformer.fit(data[\"terms\"])\n",
    "# K = len(transformer.classes_)\n",
    "# print(\"The original dataset has {} unique labels\".format(K))\n",
    "\n",
    "# counter = Counter() # is used to count the number of times each label appears in the dataset.\n",
    "# for labels in data[\"terms\"]:\n",
    "#     counter.update(labels)\n",
    "# min_count = counter.most_common(N)[-1] # returns a list of the N most common labels in the dataset, based on their frequency.\n",
    "# print(\"The {} most common labels appear at least {} times\".format(N, min_count[1]))\n",
    "\n",
    "# # Count the occurrences of each term\n",
    "# term_counts = data[\"terms\"].apply(pd.Series).stack().value_counts()\n",
    "\n",
    "# # Find the terms that occur less than min_count times\n",
    "# rare_terms = term_counts[term_counts < min_count[1]].index\n",
    "\n",
    "# # Remove rows that contain rare terms\n",
    "# data = data[~data[\"terms\"].apply(set(rare_terms).intersection).astype(bool)]\n",
    "\n",
    "# # Create the folder if not already exists, save dataset\n",
    "# if not os.path.exists(\"data\"):\n",
    "#     os.mkdir(\"data\")\n",
    "# data.to_csv(\"./data/arxiv_abstract.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Clean and sample the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "datasetPath = './data/arxiv_abstract.csv'\n",
    "data = pd.read_csv(datasetPath)\n",
    "# Drop rows with missing or duplicate values\n",
    "# data = data.dropna()\n",
    "# data = data.drop_duplicates()\n",
    "# data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# sample the data since it is too large\n",
    "# data = data.sample(frac=0.1).reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Divide the data into train, validate and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 80% training, 10% validation, 10% testing\n",
    "# train, validate, test = np.split(data, [int(.8*len(data)), int(.9*len(data))])\n",
    "# train.to_csv('./trainData/train.csv', index=False)\n",
    "# validate.to_csv('./validationData/validation.csv', index=False)\n",
    "# test.to_csv('./testData/test.csv', index=False)\n",
    "\n",
    "# # print the number of rows in each set wth its ratio\n",
    "# print(\"Train set: \", len(train), \", which is: \", len(train)/len(data))\n",
    "# print(\"Validation set: \", len(validate), \", which is: \",len(validate)/len(data))\n",
    "# print(\"Test set: \", len(test), \", which is: \",len(test)/len(data))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLTable folders\n",
    "training_mltable_path = \"./trainData/\"\n",
    "validation_mltable_path = \"./validationData/\"\n",
    "\n",
    "# Training MLTable defined locally, with local data to be uploaded\n",
    "trainData = Input(type=AssetTypes.MLTABLE, path=training_mltable_path)\n",
    "\n",
    "# Validation MLTable defined locally, with local data to be uploaded\n",
    "validationData = Input(type=AssetTypes.MLTABLE, path=validation_mltable_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configure the AutoML NLP Text Classification Multilabel training job\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Create or get an existing Azure Machine Learning compute target\n",
    "\n",
    "Now, we want to create or get an existing Azure Machine Learning compute target. The compute target is used for training machine learning models and can be thought of as a set of virtual machines that run in parallel to speed up the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target.\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import AmlCompute\n",
    "from azure.core.exceptions import ResourceNotFoundError\n",
    "\n",
    "compute_name = \"mwk\"\n",
    "\n",
    "try:\n",
    "    _ = ml_client.compute.get(compute_name)\n",
    "    print(\"Found existing compute target.\")\n",
    "except ResourceNotFoundError:\n",
    "    print(\"Creating a new compute target...\")\n",
    "    # general job parameters\n",
    "    compute_config = AmlCompute(\n",
    "        name=compute_name,\n",
    "        type=\"amlcompute\",\n",
    "        size=\"Standard_NC6\",\n",
    "        idle_time_before_scale_down=120,\n",
    "        min_instances=0,\n",
    "        max_instances=4,\n",
    "    )\n",
    "    # Finally, the new compute target is created using ml_client.begin_create_or_update(compute_config).result(). \n",
    "    # The .result() method ensures that the creation operation completes before moving on to the next step of the code.\n",
    "    ml_client.begin_create_or_update(compute_config).result()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Create the AutoML job(experiment) with the related factory-function\n",
    "\n",
    "Now, we want to create a new text classification multilabel experiment using Azure Machine Learning's automated machine learning (AutoML) functionality, with the specified configuration settings.\n",
    "\n",
    "After the AutoML experiment configuration is set up, `text_classification_multilabel_job.set_limits(timeout_minutes=exp_timeout)` is used to set the maximum amount of time that the experiment can run for.\n",
    "Once the configuration is complete and the timeout is set, the AutoML experiment can be run using `text_classification_multilabel_job.fit()` to train multiple models and find the best performing model based on the specified evaluation metric.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the AutoML job with the related factory-function.\n",
    "exp_name = \"dpv2-nlp-multilabel\"\n",
    "exp_timeout = 120\n",
    "text_classification_multilabel_job = automl.text_classification_multilabel(\n",
    "    compute=compute_name,\n",
    "    experiment_name=exp_name,\n",
    "    training_data=trainData,\n",
    "    validation_data=validationData,\n",
    "    target_column_name=\"terms\",\n",
    "    primary_metric=\"accuracy\", # specifies the evaluation metric to be used to compare the performance of different models during the AutoML experiment.\n",
    "    tags={\"Name\": \"BigData-Text-Classification-Multilabel\"},\n",
    ")\n",
    "text_classification_multilabel_job.set_limits(timeout_minutes=exp_timeout)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run the AutoML NLP Text Classification Multilabel training job\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Submit the AutoML job\n",
    "\n",
    "The `ml_client.jobs.create_or_update()` method is called with the `text_classification_multilabel_job` object as an argument. \n",
    "\n",
    "This method creates a new job or updates an existing job with the specified experiment configuration.\n",
    "\n",
    "The `create_or_update()` method returns a job object that represents the job in the Azure Machine Learning service backend.\n",
    "\n",
    "The `returned_job` variable is assigned to the job object returned by the `create_or_update()` method. \n",
    "\n",
    "The job object contains information about the job, such as its ID, status, and run history.\n",
    "\n",
    "The job is then submitted to the backend for execution. The status of the job can be tracked and monitored using the Azure Machine Learning service backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Readonly attribute primary_metric will be ignored in class <class 'azure.ai.ml._restclient.v2023_02_01_preview.models._models_py3.TextClassificationMultilabel'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created job: compute: azureml:mwk\n",
      "creation_context:\n",
      "  created_at: '2023-05-01T23:30:55.453769+00:00'\n",
      "  created_by: \"\\u0645\\u0635\\u0637\\u0641\\u0649 \\u0648\\u0627\\u0626\\u0644 \\u0643\\u0645\\\n",
      "    \\u0627\\u0644 \\u0645\\u062D\\u0645\\u062F \\u0645\\u062D\\u0645\\u062F \\u0639\\u0644\\u0649\"\n",
      "  created_by_type: User\n",
      "display_name: goofy_reggae_79wspbhc97\n",
      "experiment_name: dpv2-nlp-multilabel\n",
      "id: azureml:/subscriptions/a7ef3688-af58-4835-953c-e51f219fbd0f/resourceGroups/BigData_resource_group/providers/Microsoft.MachineLearningServices/workspaces/BigData_workspace/jobs/goofy_reggae_79wspbhc97\n",
      "limits:\n",
      "  max_concurrent_trials: 1\n",
      "  max_nodes: 1\n",
      "  max_trials: 1\n",
      "  timeout_minutes: 120\n",
      "log_verbosity: info\n",
      "name: goofy_reggae_79wspbhc97\n",
      "outputs: {}\n",
      "primary_metric: accuracy\n",
      "properties: {}\n",
      "resources:\n",
      "  instance_count: 1\n",
      "  shm_size: 2g\n",
      "services:\n",
      "  Studio:\n",
      "    endpoint: https://ml.azure.com/runs/goofy_reggae_79wspbhc97?wsid=/subscriptions/a7ef3688-af58-4835-953c-e51f219fbd0f/resourcegroups/BigData_resource_group/workspaces/BigData_workspace&tid=77255288-5298-4ea5-81aa-a13e604c30ac\n",
      "    job_service_type: Studio\n",
      "  Tracking:\n",
      "    endpoint: azureml://eastus.api.azureml.ms/mlflow/v1.0/subscriptions/a7ef3688-af58-4835-953c-e51f219fbd0f/resourceGroups/BigData_resource_group/providers/Microsoft.MachineLearningServices/workspaces/BigData_workspace?\n",
      "    job_service_type: Tracking\n",
      "status: NotStarted\n",
      "tags:\n",
      "  Name: BigData-Text-Classification-Multilabel\n",
      "target_column_name: terms\n",
      "task: text_classification_multilabel\n",
      "training_data:\n",
      "  path: azureml://datastores/workspaceblobstore/paths/LocalUpload/98ba08ba217890dfba5c355925fc453d/trainData\n",
      "  type: mltable\n",
      "type: automl\n",
      "validation_data:\n",
      "  path: azureml://datastores/workspaceblobstore/paths/LocalUpload/5781289b304807d2553258681cbdf207/validationData\n",
      "  type: mltable\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Submit the AutoML job\n",
    "\n",
    "returned_job = ml_client.jobs.create_or_update(\n",
    "    text_classification_multilabel_job\n",
    ")  # submit the job to the backend\n",
    "\n",
    "print(f\"Created job: {returned_job}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Monitor the AutoML job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client.jobs.stream(returned_job.name) # The actual execution of the job is started using the ml_client.jobs.stream() method.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Retrieve Model Information from the Best Trial of the Model\n",
    "Once all the trials complete training, we can retrieve the best model.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Obtain best child run id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain best child run id\n",
    "returned_nlp_job = ml_client.jobs.get(name=returned_job.name)\n",
    "best_child_run_id = returned_nlp_job.tags[\"automl_best_child_run_id\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Obtain the tracking URI for MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the tracking URI for MLFlow\n",
    "\n",
    "# pip install azureml-mlflow\n",
    "import mlflow\n",
    "\n",
    "# Obtain the tracking URL from MLClient\n",
    "MLFLOW_TRACKING_URI = ml_client.workspaces.get(\n",
    "    name=ml_client.workspace_name\n",
    ").mlflow_tracking_uri\n",
    "# Set the MLFLOW TRACKING URI\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "print(\"\\nCurrent tracking uri: {}\".format(mlflow.get_tracking_uri()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Get the AutoML parent Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent Run: \n",
      "<Run: data=<RunData: metrics={'AUC_macro': 0.4704729801043168,\n",
      " 'AUC_micro': 0.8810082427131436,\n",
      " 'AUC_weighted': 0.5188226592089041,\n",
      " 'accuracy': 0.6140350877192983,\n",
      " 'average_precision_score_macro': 0.1085165195178471,\n",
      " 'average_precision_score_micro': 0.7414656351057535,\n",
      " 'average_precision_score_weighted': 0.6432029684560076,\n",
      " 'balanced_accuracy': 0.0625,\n",
      " 'f1_score_macro': 0.060810810810810814,\n",
      " 'f1_score_micro': 0.7346938775510204,\n",
      " 'f1_score_weighted': 0.5837837837837838,\n",
      " 'log_loss': 3.625166160127888,\n",
      " 'norm_macro_recall': 0.14666666666666667,\n",
      " 'precision_score_macro': 0.05921052631578947,\n",
      " 'precision_score_micro': 0.9473684210526315,\n",
      " 'precision_score_weighted': 0.5684210526315789,\n",
      " 'recall_score_macro': 0.0625,\n",
      " 'recall_score_micro': 0.6,\n",
      " 'recall_score_weighted': 0.6}, params={}, tags={'Name': 'BigData-Text-Classification-Multilabel',\n",
      " 'automl_best_child_run_id': 'goofy_reggae_79wspbhc97_HD_0',\n",
      " 'fit_time_000': 'NaN',\n",
      " 'is_gpu': 'True',\n",
      " 'iteration_000': '0',\n",
      " 'mlflow.rootRunId': 'goofy_reggae_79wspbhc97',\n",
      " 'mlflow.runName': 'goofy_reggae_79wspbhc97',\n",
      " 'mlflow.user': 'مصطفى وائل كمال محمد محمد على',\n",
      " 'model_explain_run': 'best_run',\n",
      " 'pipeline_id_000': 'UnkownPipelineId',\n",
      " 'predicted_cost_000': '0',\n",
      " 'run_algorithm_000': '',\n",
      " 'run_preprocessor_000': '',\n",
      " 'score_000': '0.6140350877192983',\n",
      " 'training_percent_000': '0'}>, info=<RunInfo: artifact_uri='azureml://eastus.api.azureml.ms/mlflow/v2.0/subscriptions/a7ef3688-af58-4835-953c-e51f219fbd0f/resourceGroups/BigData_resource_group/providers/Microsoft.MachineLearningServices/workspaces/BigData_workspace/experiments/480d95c7-7e6e-4057-b4d2-133e7c157d53/runs/goofy_reggae_79wspbhc97/artifacts', end_time=1682984325076, experiment_id='480d95c7-7e6e-4057-b4d2-133e7c157d53', lifecycle_stage='active', run_id='goofy_reggae_79wspbhc97', run_name='goofy_reggae_79wspbhc97', run_uuid='goofy_reggae_79wspbhc97', start_time=1682983868667, status='FINISHED', user_id='364ea3de-a7fc-4fad-821c-38a34c5783b0'>>\n"
     ]
    }
   ],
   "source": [
    "from mlflow.tracking.client import MlflowClient\n",
    "\n",
    "# Initialize MLFlow client\n",
    "mlflow_client = MlflowClient()\n",
    "\n",
    "# Get the AutoML parent Job\n",
    "job_name = returned_job.name\n",
    "\n",
    "# Get the parent run\n",
    "mlflow_parent_run = mlflow_client.get_run(job_name)\n",
    "\n",
    "print(\"Parent Run: \")\n",
    "print(mlflow_parent_run)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Get the AutoML best child run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best child run: \n",
      "<Run: data=<RunData: metrics={'AUC_macro': 0.4704729801043168,\n",
      " 'AUC_micro': 0.8810082427131436,\n",
      " 'AUC_weighted': 0.5188226592089041,\n",
      " 'accuracy': 0.6140350877192983,\n",
      " 'average_precision_score_macro': 0.1085165195178471,\n",
      " 'average_precision_score_micro': 0.7414656351057535,\n",
      " 'average_precision_score_weighted': 0.6432029684560076,\n",
      " 'balanced_accuracy': 0.0625,\n",
      " 'f1_score_macro': 0.060810810810810814,\n",
      " 'f1_score_micro': 0.7346938775510204,\n",
      " 'f1_score_weighted': 0.5837837837837838,\n",
      " 'log_loss': 3.625166160127888,\n",
      " 'norm_macro_recall': 0.14666666666666667,\n",
      " 'precision_score_macro': 0.05921052631578947,\n",
      " 'precision_score_micro': 0.9473684210526315,\n",
      " 'precision_score_weighted': 0.5684210526315789,\n",
      " 'recall_score_macro': 0.0625,\n",
      " 'recall_score_micro': 0.6,\n",
      " 'recall_score_weighted': 0.6}, params={}, tags={'hyperparameters': '{\"ignored_argument\": 0}',\n",
      " 'mlflow.parentRunId': 'goofy_reggae_79wspbhc97_HD',\n",
      " 'mlflow.rootRunId': 'goofy_reggae_79wspbhc97',\n",
      " 'mlflow.runName': 'modest_berry_34fr9yb3',\n",
      " 'mlflow.source.name': 'hd_text_multi_labeling_dnn_driver.py',\n",
      " 'mlflow.source.type': 'JOB',\n",
      " 'mlflow.user': 'مصطفى وائل كمال محمد محمد على'}>, info=<RunInfo: artifact_uri='azureml://eastus.api.azureml.ms/mlflow/v2.0/subscriptions/a7ef3688-af58-4835-953c-e51f219fbd0f/resourceGroups/BigData_resource_group/providers/Microsoft.MachineLearningServices/workspaces/BigData_workspace/experiments/480d95c7-7e6e-4057-b4d2-133e7c157d53/runs/goofy_reggae_79wspbhc97_HD_0/artifacts', end_time=1682984270871, experiment_id='480d95c7-7e6e-4057-b4d2-133e7c157d53', lifecycle_stage='active', run_id='goofy_reggae_79wspbhc97_HD_0', run_name='modest_berry_34fr9yb3', run_uuid='goofy_reggae_79wspbhc97_HD_0', start_time=1682984169202, status='FINISHED', user_id='364ea3de-a7fc-4fad-821c-38a34c5783b0'>>\n",
      "Best child run metrics: \n",
      "{'accuracy': 0.6140350877192983, 'precision_score_macro': 0.05921052631578947, 'recall_score_macro': 0.0625, 'balanced_accuracy': 0.0625, 'average_precision_score_weighted': 0.6432029684560076, 'average_precision_score_macro': 0.1085165195178471, 'AUC_weighted': 0.5188226592089041, 'norm_macro_recall': 0.14666666666666667, 'f1_score_macro': 0.060810810810810814, 'log_loss': 3.625166160127888, 'recall_score_weighted': 0.6, 'precision_score_micro': 0.9473684210526315, 'AUC_micro': 0.8810082427131436, 'precision_score_weighted': 0.5684210526315789, 'f1_score_weighted': 0.5837837837837838, 'recall_score_micro': 0.6, 'AUC_macro': 0.4704729801043168, 'f1_score_micro': 0.7346938775510204, 'average_precision_score_micro': 0.7414656351057535}\n"
     ]
    }
   ],
   "source": [
    "# Get the AutoML best child run\n",
    "best_run = mlflow_client.get_run(best_child_run_id)\n",
    "# OR\n",
    "# best_child_run_id = mlflow_parent_run.data.tags[\"automl_best_child_run_id\"]\n",
    "print(\"Best child run: \")\n",
    "print(best_run)\n",
    "print(\"Best child run metrics: \")\n",
    "print(best_run.data.metrics)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Download the best model locally\n",
    "\n",
    "Access the results (such as Models, Artifacts, Metrics) of a previously completed AutoML Run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts downloaded in: /media/mostafa/CUFE/CMP4/2nd term/Big Data/Labs/azure lab/artifact_downloads/outputs\n",
      "Artifacts: ['all_results.json', 'conda_env_v_1_0_0.yml', 'config.json', 'generated_code', 'metrics.csv', 'mlflow-model', 'model.pkl', 'pytorch_model.bin', 'run_id.txt', 'score_script.py', 'scoring_file_v_1_0_0.py', 'special_tokens_map.json', 'tokenizer.json', 'tokenizer_config.json', 'trainer_state.json', 'training_args.bin', 'train_results.json', 'vocab.txt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from mlflow.artifacts import download_artifacts\n",
    "\n",
    "# Create local folder\n",
    "local_dir = \"./artifact_downloads\"\n",
    "if not os.path.exists(local_dir):\n",
    "    os.mkdir(local_dir)\n",
    "# Download run's artifacts/outputs\n",
    "local_path = download_artifacts(\n",
    "    run_id=best_run.info.run_id, artifact_path=\"outputs\", dst_path=local_dir\n",
    ")\n",
    "print(\"Artifacts downloaded in: {}\".format(local_path))\n",
    "print(\"Artifacts: {}\".format(os.listdir(local_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conda.yaml',\n",
       " 'data',\n",
       " 'input_example.json',\n",
       " 'MLmodel',\n",
       " 'python_env.yaml',\n",
       " 'requirements.txt']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the contents of the MLFlow model folder\n",
    "os.listdir(\"./artifact_downloads/outputs/mlflow-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
